{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import pandas as pd\n",
    "import utilities.misc as um\n",
    "import utilities.constants as uc\n",
    "import utilities.display as ud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "from twitter_api.twitter_api import get_all_tweets_from_friends\n",
    "\n",
    "import re\n",
    "\n",
    "import feather\n",
    "\n",
    "from nltk_wrapper.nltk_wrapper import get_sentiment, clean_tokenize\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't save the dump with list\n",
    "path=\"D:\\\\data\\\\twitter\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished friend number 1/45, total tweet collected is 698\n",
      "finished friend number 2/45, total tweet collected is 371\n",
      "finished friend number 3/45, total tweet collected is 576\n",
      "finished friend number 4/45, total tweet collected is 468\n",
      "finished friend number 5/45, total tweet collected is 907\n",
      "finished friend number 6/45, total tweet collected is 2582\n",
      "finished friend number 7/45, total tweet collected is 738\n",
      "finished friend number 8/45, total tweet collected is 97\n",
      "finished friend number 9/45, total tweet collected is 2127\n",
      "finished friend number 10/45, total tweet collected is 4\n",
      "finished friend number 11/45, total tweet collected is 348\n",
      "finished friend number 12/45, total tweet collected is 343\n",
      "finished friend number 13/45, total tweet collected is 1099\n",
      "finished friend number 14/45, total tweet collected is 747\n",
      "finished friend number 15/45, total tweet collected is 1092\n",
      "finished friend number 16/45, total tweet collected is 12\n",
      "finished friend number 17/45, total tweet collected is 11\n",
      "finished friend number 18/45, total tweet collected is 3229\n",
      "finished friend number 19/45, total tweet collected is 32\n",
      "finished friend number 20/45, total tweet collected is 89\n",
      "finished friend number 21/45, total tweet collected is 570\n",
      "finished friend number 22/45, total tweet collected is 5\n",
      "finished friend number 23/45, total tweet collected is 228\n",
      "finished friend number 24/45, total tweet collected is 687\n",
      "finished friend number 25/45, total tweet collected is 95\n",
      "finished friend number 26/45, total tweet collected is 481\n",
      "finished friend number 27/45, total tweet collected is 84\n",
      "finished friend number 28/45, total tweet collected is 387\n",
      "finished friend number 29/45, total tweet collected is 30\n",
      "finished friend number 30/45, total tweet collected is 559\n",
      "finished friend number 31/45, total tweet collected is 6\n",
      "finished friend number 32/45, total tweet collected is 40\n",
      "finished friend number 33/45, total tweet collected is 831\n",
      "finished friend number 34/45, total tweet collected is 1019\n",
      "finished friend number 35/45, total tweet collected is 3215\n",
      "finished friend number 36/45, total tweet collected is 259\n",
      "finished friend number 37/45, total tweet collected is 20\n",
      "finished friend number 38/45, total tweet collected is 861\n",
      "finished friend number 39/45, total tweet collected is 334\n",
      "finished friend number 40/45, total tweet collected is 330\n",
      "finished friend number 41/45, total tweet collected is 478\n",
      "finished friend number 42/45, total tweet collected is 42\n",
      "finished friend number 43/45, total tweet collected is 26\n",
      "finished friend number 44/45, total tweet collected is 3214\n",
      "finished friend number 45/45, total tweet collected is 68\n"
     ]
    }
   ],
   "source": [
    "start=pd.datetime(2019,12,1)\n",
    "end=um.today_date()\n",
    "\n",
    "all_tweets=get_all_tweets_from_friends(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study=all_tweets[all_tweets['lang']=='en'].copy()\n",
    "study['sentiment']=study['text'].map(lambda x: get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data by hashtag\n",
    "study_hash=study[study['hashtags'].map(lambda x: len(x))>0]\n",
    "collector=[]\n",
    "for i,row in enumerate(study_hash.index):\n",
    "    info_i=study_hash.iloc[i]\n",
    "    hash_i=info_i['hashtags']\n",
    "    date_i=info_i['date']\n",
    "    retweets_i=info_i['retweets']\n",
    "    likes_i=info_i['likes']\n",
    "    \n",
    "    res_i=pd.DataFrame(index=hash_i,columns=['date','retweets','likes'],data=[[date_i,retweets_i,likes_i]])\n",
    "    collector.append(res_i)\n",
    "hash_all=pd.concat(collector)\n",
    "hash_all.index.name='hashtag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word cloud\n",
    "collector=[]\n",
    "for i, idx in enumerate(study.index):\n",
    "    info_i=study.iloc[i]\n",
    "    tweet_i=clean_tokenize(info_i['text'])\n",
    "    res_i=pd.Series(index=np.arange(0,len(tweet_i)),data=tweet_i).rename('word').to_frame()\n",
    "    res_i['date']=info_i['date']\n",
    "    res_i['tweet_id']=info_i['tweet_id']\n",
    "    res_i['likes']=info_i['likes']\n",
    "    res_i['retweets']=info_i['retweets']\n",
    "    collector.append(res_i)\n",
    "words=pd.concat(collector,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump some data\n",
    "feather.write_dataframe(hash_all.reset_index(),path+'hash.feather')\n",
    "feather.write_dataframe(.drop(['hashtags','mentions_id','mentions_name'],axis=1),path+'text.feather')\n",
    "feather.write_dataframe(words,path+'words.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
